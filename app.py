import streamlit as st
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import os
import ast

# --- Cáº¥u hÃ¬nh ---
st.set_page_config(page_title="AI Matching", page_icon="ğŸ§©", layout="centered")

# --- Model embedding ---
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# --- Load dá»¯ liá»‡u ---
@st.cache_data
def load_data():
    csv_path = "data/user_data.csv"
    
    if os.path.exists(csv_path):
        try:
            df = pd.read_csv(csv_path)
            # Chuyá»ƒn chuá»—i -> list láº¡i cho cÃ¡c cá»™t chá»©a danh sÃ¡ch
            for col in ["MÃ´n há»c", "Thá»i gian ráº£nh"]:
                df[col] = df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)
            print(f"ÄÃ£ táº£i dá»¯ liá»‡u tá»« {csv_path}", file=os.sys.stderr)
            return df
        except Exception as e:
            print(f"KhÃ´ng thá»ƒ Ä‘á»c file CSV: {e}. Sá»­ dá»¥ng dá»¯ liá»‡u máº«u.", file=os.sys.stderr)
    
    # Dá»¯ liá»‡u máº«u (fallback)
    data = {
        "TÃªn": ["Ngá»c", "Lan", "Nam", "Vy", "Báº£o"],
        "MÃ´n há»c": [["CÆ¡ sá»Ÿ láº­p trÃ¬nh"], ["ToÃ¡n rá»i ráº¡c"], ["Ká»¹ nÄƒng má»m", "ToÃ¡n rá»i ráº¡c"], ["Nháº­p mÃ´n CNTT"], ["Ká»¹ nÄƒng má»m"]],
        "Thá»i gian ráº£nh": [["SÃ¡ng", "Chiá»u"], ["Chiá»u"], ["Tá»‘i"], ["SÃ¡ng"], ["SÃ¡ng", "Chiá»u"]],
        "Giá»›i tÃ­nh": ["Ná»¯", "Ná»¯", "Nam", "Ná»¯", "Nam"],
        "Sá»Ÿ thÃ­ch": [
            "ThÃ­ch code web, Ä‘á»c sÃ¡ch cÃ´ng nghá»‡",
            "YÃªu thÃ­ch ToÃ¡n há»c vÃ  logic",
            "ThÃ­ch lÃ m viá»‡c nhÃ³m, nÃ³i chuyá»‡n nhiá»u",
            "YÃªu nghá»‡ thuáº­t, thÃ­ch thiáº¿t káº¿",
            "ThÃ­ch nghiÃªn cá»©u AI vÃ  cÃ´ng nghá»‡ má»›i"
        ],
        "TÃ­nh cÃ¡ch": [
            "Láº­p di, kiÃªn nháº«n",
            "NÄƒng Ä‘á»™ng, hÆ°á»›ng ngoáº¡i",
            "Vui váº», thÃ¢n thiá»‡n",
            "Tráº§m tÃ­nh, sÃ¡ng táº¡o",
            "PhÃ¢n tÃ­ch logic, Ã­t nÃ³i"
        ]
    }
    return pd.DataFrame(data)

df = load_data()

# --- TÃ­nh vector mÃ´ táº£ cÃ¡ nhÃ¢n ---
@st.cache_data
def compute_vectors(df):
    df["vector"] = df.apply(lambda row: model.encode(
        row["Sá»Ÿ thÃ­ch"] + " " + row["TÃ­nh cÃ¡ch"]
    ), axis=1)
    return df

df = compute_vectors(df)

# --- UI ngÆ°á»i dÃ¹ng ---
st.title("ğŸ§© Gá»£i Ã½ báº¡n há»c phÃ¹ há»£p báº±ng AI")
st.markdown("### Nháº­p thÃ´ng tin cá»§a báº¡n Ä‘á»ƒ tÃ¬m ngÆ°á»i há»c há»£p nháº¥t ğŸ’¡")

user_subjects = st.multiselect(
    "ğŸ“˜ MÃ´n há»c báº¡n quan tÃ¢m:",
    ["CÆ¡ sá»Ÿ láº­p trÃ¬nh", "ToÃ¡n rá»i ráº¡c", "Ká»¹ nÄƒng má»m", "Nháº­p mÃ´n CNTT"]
)

user_time = st.multiselect(
    "ğŸ•’ Thá»i gian ráº£nh cá»§a báº¡n:",
    ["SÃ¡ng", "Chiá»u", "Tá»‘i"]
)

col1, col2 = st.columns(2)
with col1:
    user_gender = st.selectbox("ğŸš» Giá»›i tÃ­nh cá»§a báº¡n:", ["Nam", "Ná»¯", "KhÃ¡c"])
with col2:
    target_gender = st.multiselect("ğŸ¯ Báº¡n muá»‘n tÃ¬m báº¡n há»c giá»›i tÃ­nh:", ["Nam", "Ná»¯", "KhÃ¡c"])

user_hobby = st.text_area("ğŸ¨ Sá»Ÿ thÃ­ch cá»§a báº¡n lÃ  gÃ¬?")
user_personality = st.text_area("ğŸ’¬ MÃ´ táº£ tÃ­nh cÃ¡ch cá»§a báº¡n:")

if st.button("ğŸ” TÃ¬m báº¡n há»c phÃ¹ há»£p", use_container_width=True):
    if not user_subjects or not user_time:
        st.warning("âš ï¸ HÃ£y nháº­p Ä‘áº§y Ä‘á»§ mÃ´n há»c vÃ  thá»i gian ráº£nh trÆ°á»›c khi tÃ¬m nhÃ©!")
    else:
        user_vector = model.encode(user_hobby + " " + user_personality)

        filtered_df = df[df["Giá»›i tÃ­nh"].isin(target_gender)] if target_gender else df

        # --- Ãp dá»¥ng quy táº¯c cá»©ng: chá»‰ giá»¯ ngÆ°á»i cÃ³ Ã­t nháº¥t 1 mÃ´n vÃ  1 thá»i gian trÃ¹ng ---
        def valid_match(row):
            subject_overlap = any(sub in row["MÃ´n há»c"] for sub in user_subjects)
            time_overlap = any(t in row["Thá»i gian ráº£nh"] for t in user_time)
            return subject_overlap and time_overlap

        valid_candidates = filtered_df[filtered_df.apply(valid_match, axis=1)].copy()

        if len(valid_candidates) == 0:
            st.error("ğŸ˜¥ KhÃ´ng tÃ¬m tháº¥y báº¡n há»c nÃ o phÃ¹ há»£p vá»›i mÃ´n há»c vÃ  thá»i gian ráº£nh cá»§a báº¡n.")
        else:
            similarities = cosine_similarity([user_vector], list(valid_candidates["vector"]))
            valid_candidates["Äá»™ há»£p (%)"] = (similarities[0] * 100).round(2)

            top_matches = valid_candidates.sort_values(by="Äá»™ há»£p (%)", ascending=False).head(3)

            st.markdown("## ğŸ” Káº¿t quáº£ gá»£i Ã½:")

            for _, row in top_matches.iterrows():
                st.markdown(f"""
                **ğŸ‘¤ TÃªn:** {row['TÃªn']}  
                **ğŸ“˜ MÃ´n há»c:** {', '.join(row['MÃ´n há»c'])}  
                **ğŸ•’ Thá»i gian ráº£nh:** {', '.join(row['Thá»i gian ráº£nh'])}  
                **ğŸš» Giá»›i tÃ­nh:** {row['Giá»›i tÃ­nh']}  
                **ğŸ¨ Sá»Ÿ thÃ­ch:** {row['Sá»Ÿ thÃ­ch']}  
                **ğŸ’¬ TÃ­nh cÃ¡ch:** {row['TÃ­nh cÃ¡ch']}  
                **ğŸ’¡ Äá»™ há»£p:** `{row['Äá»™ há»£p (%)']}%`
                """)
                st.divider()
